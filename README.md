# RAG LangChain Pipeline Project

This project implements a Retrieval-Augmented Generation (RAG) pipeline using LangChain and a Hugging Face model as the large language model (LLM). RAG is a method of combining retrieval with generative models to improve the quality of responses to queries by leveraging relevant documents from a knowledge base. This project includes:

- **Embedding Generation** using Sentence-Transformers for encoding the text.
- **Vector Store** based on FAISS (Facebook AI Similarity Search) for efficient similarity searching.
- **Retrieval-Augmented Generation Chain** using LangChain and a text generation model from Hugging Face.
- **Data and Responses Storage**: A `responses.pdf` file in the `data` directory showcases example outputs from the RAG pipeline.

## Project Structure

- `src/`: Contains all core code for the RAG pipeline.
  - `rag_pipeline.py`: Builds and executes the RAG pipeline, combining retrieval with a Hugging Face LLM.
  - `utils.py`: Contains helper functions for text chunking and processing.
  - `main.py`: Entry point to run the RAG pipeline with your own query.
- `data/`: Contains all the input documents and responses of the model
  - Contains the `responses.pdf` file with sample responses generated by the RAG pipeline.
  - Contains the `document.pdf` file which is used as a input pdf for the queries asked.

## Prerequisites

To get started, ensure you have the following installed:
- Python 3.8 or later
- An NVIDIA GPU (optional, but recommended for faster processing)
- Required packages listed in `requirements.txt` (install with `pip install -r requirements.txt`)

## How to Run the Project

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/YourUsername/RAG-Langchain-Pipeline.git
   cd RAG-Langchain-Pipeline
   
2. **Installing Dependencies**:
   ```bash
   git clone https://github.com/YourUsername/RAG-Langchain-Pipeline.git
   cd RAG-Langchain-Pipeline
